{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch06 数据加载、存储与文件格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取文本格式的数据\n",
    "#### 基本读取\n",
    "- read_csv\n",
    "- read_table （已经废弃， 原来的接口并入read_csv）\n",
    "- read_fwf\n",
    "- read_clipboard\n",
    "\n",
    "**数据读取注意事项**\n",
    "- 索引\n",
    "- 类型推断和数据转换\n",
    "- 日期解析\n",
    "- 迭代\n",
    "- 不规整数据问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! cat pydata/ch06/ex1.csv\n",
    "df = pd.read_csv('../pydata/ch06/ex1.csv')\n",
    "print( df )\n",
    "## read_table is deprecated\n",
    "pd.read_table('../pydata/ch06/ex1.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat pydata/ch06/ex2.csv\n",
    "\n",
    "print('-'*32)\n",
    "df = pd.read_csv('../pydata/ch06/ex2.csv', header=None)\n",
    "print( df )\n",
    "\n",
    "print('-'*32)\n",
    "df = pd.read_csv('../pydata/ch06/ex2.csv', \n",
    "            names=['a','b','c','d', 'message']\n",
    "           )\n",
    "print( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat pydata/ch06/csv_mindex.csv\n",
    "\n",
    "print('-'*32)\n",
    "parsed = pd.read_csv('../pydata/ch06/csv_mindex.csv')\n",
    "print( parsed )\n",
    "\n",
    "print('-'*32)\n",
    "parsed = pd.read_csv('../pydata/ch06/csv_mindex.csv', index_col=['key1', 'key2'])\n",
    "print(parsed)\n",
    "parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**用正则表达式来作为read_table的分隔符** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list( open( '../pydata/ch06/ex3.txt') )\n",
    "\n",
    "#result = pd.read_csv('pydata/ch06/ex3.txt', sep='\\s+')\n",
    "result = pd.read_csv('../pydata/ch06/ex3.txt', sep='\\s+')\n",
    "\n",
    "[ l, result ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat pydata/ch06/ex4.csv\n",
    "r1 = pd.read_csv('../pydata/ch06/ex4.csv')\n",
    "r2 = pd.read_csv('../pydata/ch06/ex4.csv', skiprows=[0,2,3])\n",
    "[r1, r2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! cat pydata/ch06/ex5.csv\n",
    "result = pd.read_csv('../pydata/ch06/ex5.csv')\n",
    "result\n",
    "pd.isnull(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('../pydata/ch06/ex5.csv', na_values=['NULL'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''可以用一个字典为各列指定不同的NA标记值'''\n",
    "sentinels = {\n",
    "    'message': ['foo', 'NA'],\n",
    "    'something': ['two']\n",
    "}\n",
    "result = pd.read_csv('../pydata/ch06/ex5.csv', na_values=sentinels)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**read_csv函数的参数 P178**\n",
    "\n",
    "参数 | 说明\n",
    "--- | ---\n",
    " path | URL\n",
    " sep/delimiter | 分隔符\n",
    " header | 用作列名的行号。默认为0（第一行\n",
    " index_col | 用作行索引的列编号或列名\n",
    " names | 用于结果的列名列表， 结合header=None\n",
    " skiprows | 需要忽略的行数\n",
    " na_values | 用于替代NA的值\n",
    " comment | 用于将注释信息从行尾拆分出去的字符\n",
    " parse_dates | 解析日期\n",
    " keep_date_col | 用于连接多列解析日期\n",
    " converters | 由列号/列名跟函数之间的映射关系组成的字典。\n",
    "             | 例如：{'foo': f}会对foo列应用函数f\n",
    "dayfirst | 当解析有歧义的日期时，将其看作国际格式\n",
    "nrows | 需要读取的行数\n",
    "iterator | 返回一个textParser以便逐块读取文件\n",
    "chunksize | 文件块的大小\n",
    "skip_footer | 从末尾算起，忽略的行数\n",
    "verbose | 打印各种解析器信息\n",
    "encoding | 用于unicode的文本编码格式，比如utf-8\n",
    "squeeze | 如果仅仅是一列，则返回为Series\n",
    "thousands | 千分位分隔符，如 ， or .\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逐块读取文本文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! head -n 3 pydata/ch06/ex6.csv\n",
    "result = pd.read_csv('../pydata/ch06/ex6.csv')\n",
    "result.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = pd.read_csv('../pydata/ch06/ex6.csv', chunksize=1000)\n",
    "tot = Series([])\n",
    "\n",
    "for piece in chunker:\n",
    "    tot = tot.add(piece['key'].value_counts(), fill_value=0)\n",
    "\n",
    "tot = tot.sort_index(ascending=False)\n",
    "print( tot[:10] )\n",
    "print( '-'*32 )\n",
    "print(  tot.sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将数据写出到文本格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('../pydata/ch06/ex5.csv')\n",
    "print(data)\n",
    "\n",
    "print('-'*32)\n",
    "data.to_csv('../pydata/ch06/out.csv')\n",
    "! cat pydata/ch06/out.csv\n",
    "\n",
    "print('-'*32)\n",
    "import sys\n",
    "data.to_csv(sys.stdout, sep='|')\n",
    "\n",
    "print('-'*32)\n",
    "data.to_csv(sys.stdout, na_rep='NULL')\n",
    "\n",
    "print('-'*32)\n",
    "data.to_csv(sys.stdout, index=False, header=False)\n",
    "\n",
    "print('-'*32)\n",
    "data.to_csv(sys.stdout, index=False, header=False,\n",
    "            columns=list('abd')\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Series也有一个to_csv方法**\n",
    "这也是一个被废弃的使用方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range('1/1/2000', periods=7)\n",
    "ts = Series(np.arange(7), index=dates)\n",
    "ts.to_csv(sys.stdout)\n",
    "\n",
    "ts.to_csv('../pydata/ch06/out.csv')\n",
    "ts.from_csv('../pydata/ch06/out.csv', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 手工处理分隔符格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat pydata/ch06/ex7.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open('../pydata/ch06/ex7.csv')\n",
    "reader = csv.reader(f)\n",
    "for line in reader:\n",
    "    print(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = list(csv.reader(open('../pydata/ch06/ex7.csv' )))\n",
    "header, values = lines[0], lines[1:]\n",
    "data_dict = {\n",
    "    h:v for h,v in zip(header, zip(*values))\n",
    "}\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSV文件的形式有很多，只需要定义csv.Dialect的子类即可以定义出新格式**\n",
    "- 分隔符\n",
    "- 字符串引用约定\n",
    "- 行结束符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dialect(csv.Dialect):\n",
    "    lineterminator = '\\n'\n",
    "    delimiter = ';'\n",
    "    quotechar = '\\\"'\n",
    "    quoting = 0\n",
    "\n",
    "reader = csv.reader(\n",
    "    open('../pydata/ch06/ex7.csv'), \n",
    "    dialect=my_dialect)\n",
    "\n",
    "lines = list(reader)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSV语支选项**\n",
    "- delimiter        分隔符\n",
    "- lineterminator   行结束符\n",
    "- qtotechar        字符引用符号\n",
    "- quoting          引用约定\n",
    "- skipinitialspace 忽略分隔符后面的分隔符\n",
    "- doublequote\n",
    "- escapechar       转义字符\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mydata.csv', 'w') as f:\n",
    "    writer = csv.writer(f, dialect=my_dialect)\n",
    "    writer.writerow(('one','two','three'))\n",
    "    writer.writerow(('1','2','3'))\n",
    "\n",
    "!cat mydata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON 数据集\n",
    "P184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = \"\"\" \n",
    "{\n",
    "\"name\": \"Wes\",\n",
    "\"places_lived\": [\"United States\", \"Spain\", \"Germany\"], \n",
    "\"pet\": null,\n",
    "\"siblings\": [{\"name\": \"Scott\", \"age\": 25, \"pet\": \"Zuko\"},\n",
    "             {\"name\": \"Katie\", \"age\": 33, \"pet\": \"Cisco\"}]\n",
    "} \n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "result = json.loads(obj)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asjson = json.dumps(result)\n",
    "asjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siblings = DataFrame(result['siblings'], columns=['name', 'age'])\n",
    "siblings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XML和HTML: Web信息收集\n",
    "Python有许多可以阅读HTML和XML格式的库，lxml就是一个常用的\n",
    "- lxml.html\n",
    "- lxml.objectify\n",
    "\n",
    "\n",
    "从yahoo金融下载一些信息.找到你希望获取数据的URL，利用urllib2将其打开，然后用lxml解析得到的数据流"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.html import parse\n",
    "from urllib2 import urlopen\n",
    "\n",
    "#parsed = parse()\n",
    "doc = parsed.getroot()\n",
    "\n",
    "links = doc.findall('.//a')\n",
    "links[15:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用lxml.objectify解析XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import objectify \n",
    "path = 'Performance_MNR.xml'\n",
    "parsed = objectify.parse(open(path))\n",
    "root = parsed.getroot()\n",
    "\n",
    "data = []\n",
    "skip_fields = ['PARENT_SEQ', 'INDICATOR_SEQ', 'DESIRED_CHANGE','DECIMAL_PLACES']\n",
    "\n",
    "for elt in root.INDICATOR:\n",
    "    el_data = {}\n",
    "    for child in elt.getchildren():\n",
    "        if child.tag in skip_fields:\n",
    "            continue\n",
    "        el_data[child.tag] = child.pyval\n",
    "    data.append(el_data)\n",
    "    \n",
    "perf = DataFrame(data)\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from StringIO import StringIO\n",
    "tag = '<a href=\"http://www.google.com>\"Google</a>'\n",
    "root = objectify.parse(StringIO(tag).getroot())\n",
    "print( root )\n",
    "\n",
    "root.get('href')\n",
    "root.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二进制数据格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用数据的二进制格式存储最简单的办法之一是使用Python内置的pickel序列化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv('../pydata/ch06/ex1.csv')\n",
    "print ( frame )\n",
    "frame.save('../pydata/ch06/frame_pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用HDF5格式 \n",
    "- hierarchical data format\n",
    "- HDF5可以高效读写磁盘上以二进制格式存储的科学数据\n",
    "- 如果需要处理海量数据，PyTables和h5py是好选择\n",
    "pandas有一个最小化的类似于字典的HDFStore类，它通过PyTables存储pandas对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "store  = pd.HDFStore('mydata.h5')\n",
    "store['obj1'] = frame\n",
    "store['obj1_col'] = frame['a']\n",
    "\n",
    "print( store )\n",
    "print( store['obj1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取Microsoft Excel文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls_file = pd.ExcelFile('data.xls')\n",
    "table = xls_file.parse('Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用htmp和Web API\n",
    "很多网站都有一些通过JSON或者其他格式提供数据的公共API。\n",
    "推荐的简单办法是：**requests包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'http://search.twitter.com/search.json?q=python%20pandas'\n",
    "resp = requests.get(url)\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.loads(resp.text)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweet_feilds = ['created_at', 'from_user', 'id', 'text']\n",
    "tweets = DataFrame(data['results'], columns=tweet_feilds)\n",
    "print ( tweets )\n",
    "print ( tweets.loc[7] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "query = \"\"\"\n",
    "CREATE TABLE test\n",
    "(a VARCHAR(20), b VARCHAR(20),\n",
    "c REAL, d INTEGER );\"\"\"\n",
    "\n",
    "con = sqlite3.connect(':memory:') \n",
    "con.execute(query)\n",
    "con.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Atlanta', 'Georgia', 1.25, 6), ('Tallahassee', 'Florida', 2.6, 3), ('Sacramento', 'California', 1.7, 5)]\n",
    "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\n",
    "con.executemany(stmt, data) \n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = con.execute('select * from test')\n",
    "rows = cursor.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " DataFrame(rows, columns=zip(*cursor.description)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.io.sql as sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql.read_frame('select * from test', con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用MongoDB中的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "con = pymongo.Connection('localhost', port=27017)\n",
    "tweets = con.db.tweets\n",
    "\n",
    "import requests, json\n",
    "url = 'http://search.twitter.com/search.json?q=python%20pandas' data = json.loads(requests.get(url).text)\n",
    "for tweet in data['results']:\n",
    "    tweets.save(tweet)\n",
    "\n",
    "cursor = tweets.find({'from_user': 'wesmckinn'})\n",
    "\n",
    "tweet_fields = ['created_at', 'from_user', 'id', 'text'] \n",
    "result = DataFrame(list(cursor), columns=tweet_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
