{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据规整化： 清理、转换、合并、重塑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas对象中的数据可以通过一些内置的方式进行合并\n",
    "- pandas.merge 可以根据一个或者多个健将不同DataFrame中的行连接起来\n",
    "- pandas.concat 可以沿着一个轴将多个对象堆叠到一起\n",
    "- combine_first 重复数据编接，用一个对象中的值填充另一个对象中的缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据库风格的DataFrame合并\n",
    "- merge的参数\n",
    "    - left 左df\n",
    "    - right 右df\n",
    "    - on 连接列，未指定则是交集\n",
    "    - left_on 左侧连接列\n",
    "    - right_on 右侧连接列\n",
    "    - left_index 左侧的行索引用作连接健\n",
    "    - right_index 右...\n",
    "    - sort 根据连接健排序，默认是True\n",
    "    - suffixes 字符串值元组\n",
    "    - copy 默认总是复制，除非设置为False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, Series\n",
    "df1 = DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], \n",
    "                 'data1': range(7)})\n",
    "\n",
    "df2 = DataFrame({'key': ['a', 'b', 'd'], \n",
    "                 'data2': range(3)})\n",
    "\n",
    "print ( df1 ) ;print( '-'*32 ) \n",
    "print ( df2 ) ; print( '-'*32 )\n",
    "print ( pd.merge(df1, df2)) ; print( '-'*32 )\n",
    "print ( pd.merge(df1, df2, on='key') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = DataFrame({'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], \n",
    "                 'data1': range(7)})\n",
    "\n",
    "df4 = DataFrame({'rkey': ['a', 'b', 'd'], \n",
    "                 'data2': range(3)})\n",
    "\n",
    "pd.merge(df3, df4, left_on='lkey', right_on='rkey')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( pd.merge(df1, df2, how='inner') ) ; print('-'*32)\n",
    "print ( pd.merge(df1, df2, how='outer') ) ; print('-'*32)\n",
    "print ( pd.merge(df1, df2, how='left') )  ; print('-'*32)\n",
    "print ( pd.merge(df1, df2, how='right') ) ; print('-'*32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 多对多的合并操作非常简单，无需额外的工作\n",
    "- 多对多连接产生的结果是行的**笛卡尔积**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'], \n",
    "                 'data1': range(6)})\n",
    "df2 = DataFrame({'key': ['a', 'b', 'a', 'b', 'd'], \n",
    "                 'data2': range(5)})\n",
    "\n",
    "print ( df1 ) ;print('-'*32)\n",
    "print ( df2 ) ;print('-'*32)\n",
    "print ( pd.merge(df1, df2, on='key', how='left') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要根据多个健进行合并，传入一个由列名组成的列表即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "left = DataFrame({'key1': ['foo', 'foo', 'bar'], \n",
    "                  'key2': ['one', 'two', 'one'],\n",
    "                  'lval': [1, 2, 3]})\n",
    "\n",
    "right = DataFrame({'key1': ['foo', 'foo', 'bar', 'bar'], \n",
    "                   'key2': ['one', 'one', 'one', 'two'],\n",
    "                   'rval': [4, 5, 6, 7]})\n",
    "\n",
    "print ( left )\n",
    "print ( right )\n",
    "pd.merge(left, right, on=['key1', 'key2'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, on='key1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on='key1', suffixes=('_left', '_right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 索引上的合并\n",
    "    有时候，DataFrame中的连接健位于其索引中。\n",
    "    传入left_index=True或right_index=True以说明索引应该被用作连接健"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "left1 = DataFrame(\n",
    "    {\n",
    "        'key': list('abaabc'),\n",
    "        'value':range(6)\n",
    "    }\n",
    ")\n",
    "\n",
    "right1 = DataFrame(\n",
    "    {\n",
    "        'group_val': [3.5, 7]\n",
    "    },\n",
    "    index=['a','b']\n",
    ")\n",
    "\n",
    "print(left1) ; print('-'*32)\n",
    "print(right1) ; print('-'*32)\n",
    "\n",
    "d = pd.merge(left1, right1,left_on='key', \n",
    "         right_index=True)\n",
    "\n",
    "print( d ) ; print('-'*32)\n",
    "\n",
    "d = pd.merge(left1, right1,left_on='key', \n",
    "         right_index=True, how='outer')\n",
    "print( d ) ; print('-'*32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**层次化索引**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lefth = DataFrame(\n",
    "    {\n",
    "    'key1':['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada'],\n",
    "    'key2':[2000,2001,2002,2001,2002],\n",
    "    'data':np.arange(5)\n",
    "    }\n",
    ")\n",
    "\n",
    "righth = DataFrame(\n",
    "    np.arange(12).reshape((6,2)),\n",
    "    index=[\n",
    "        ['Nevada', 'Nevada','Ohio','Ohio','Ohio','Ohio'],\n",
    "        [2001,2000,2000,2000,2001,2002]\n",
    "          ],\n",
    "    columns=['event1', 'event2']\n",
    ")\n",
    "print( lefth )\n",
    "print( righth )\n",
    "\n",
    "d = pd.merge( lefth,righth,left_on=['key1','key2'], \n",
    "        right_index=True)\n",
    "print(d) ;print('-'*32)\n",
    "\n",
    "d = pd.merge( lefth,righth,left_on=['key1','key2'], \n",
    "        right_index=True, how='outer')\n",
    "print(d) ;print('-'*32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left2 = DataFrame(\n",
    "    np.arange(1,7).reshape((3,2)),\n",
    "    index=list('ace'),\n",
    "    columns=['Ohio','Nevada']\n",
    ")\n",
    "right2 = DataFrame(\n",
    "    np.arange(7,15).reshape(4,2),\n",
    "    index=list('bcde'),\n",
    "    columns=['Missouri','Alabama']\n",
    ")\n",
    "\n",
    "print( left2 ) ; print( '-'*32 )\n",
    "print( right2 ) ; print( '-'*32 )\n",
    "pd.merge(left2, right2, how='outer', \n",
    "         left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataFrame还有一个join实例方法，它能更为方便地实现按索引合并**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left2.join(right2, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(left1);print('-'*32)\n",
    "print(right1);print('-'*32)\n",
    "left1.join(right1,on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another = DataFrame(\n",
    "    np.arange(7,15).reshape((4,2)),\n",
    "    index=list('acef'),\n",
    "    columns=['New York', 'Oregon']\n",
    ")\n",
    "d1=left2.join([right2, another])\n",
    "d2=left2.join([right2, another], how='outer')\n",
    "[d1,d2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 轴向连接\n",
    "另一种数据合并运算也被称作连接(concatenation),绑定(binding),堆叠（stacking）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(12).reshape((3,4))\n",
    "r = np.concatenate([arr,arr], axis=0)\n",
    "print( r ) ; print('-'*32)\n",
    "r = np.concatenate([arr,arr], axis=1)\n",
    "print( r ) ; print('-'*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = Series([0,1], index=['a','b'])\n",
    "s2 = Series([2,3,4],index=['c','d','e'] )\n",
    "s3 = Series([5,6], index=['f','g'])\n",
    "\n",
    "d=pd.concat([s1,s2,s3],axis=0)\n",
    "print( d ) ;print('-'*32)\n",
    "\n",
    "d=pd.concat([s1,s2,s3], axis=1,sort=True)\n",
    "print( d ) ; print('-'*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4 = pd.concat([s1 * 5, s3])\n",
    "\n",
    "r = pd.concat([s1,s4], axis=1,sort=True)\n",
    "print( r ) ; print('-'*32)\n",
    "\n",
    "r = pd.concat([s1, s4], axis=1, join='inner',sort=True)\n",
    "print( r ) ; print('-'*32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**可以通过join_axes指定要在其他轴上使用的索引**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([s1,s4], axis=1,\n",
    "         join_axes=[['a','c','b','e']],\n",
    "          sort=False\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([s1,s2,s3], \n",
    "                   keys=['one','two','three']\n",
    "                  )\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result.unstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果沿着axis=1对Series进行合并，则keys就会成为DataFrame的列头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([s1,s2,s3], \n",
    "                   keys=['one','two','three'],\n",
    "                   axis=1,sort=False\n",
    "                  )\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = DataFrame(\n",
    "    np.arange(6).reshape((3,2)),\n",
    "    index=list('abd'),\n",
    "    columns=['one','two']\n",
    ")\n",
    "\n",
    "df2 = DataFrame(\n",
    "    np.arange(4).reshape((2,2))+5,\n",
    "    index=list('ac'),\n",
    "    columns=['three', 'four']\n",
    ")\n",
    "\n",
    "d = pd.concat([df1,df2], \n",
    "          axis=0,sort=True,\n",
    "          keys=['level1', 'level2']\n",
    "         )\n",
    "print( d ) ; print('-'*32)\n",
    "\n",
    "d = pd.concat([df1,df2], \n",
    "          axis=1,sort=True,\n",
    "          keys=['level1', 'level2']\n",
    "         )\n",
    "print( d ) ; print('-'*32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***如果传入的不是列表，而是字典，那么字典的健会被当作keys选项的值***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    {\n",
    "        'level1':df1,\n",
    "        'level2':df2\n",
    "    },\n",
    "    axis=1,sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ignore_index=True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = DataFrame(np.random.randn(3,4),\n",
    "                columns=list('abcd')\n",
    "               )\n",
    "df2 = DataFrame(np.random.randn(2,3),\n",
    "                columns=list('bda')\n",
    "               )\n",
    "pd.concat([df1,df2], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**concat函数的参数**\n",
    "- objs  列表或者字典\n",
    "- axis  指明连接的轴向\n",
    "- join inner/outer 默认是outer，索引是按照交集还是并集合并\n",
    "- join_axes 指明用于其他n-1条轴上的索引 \n",
    "- keys 与objs有关的值\n",
    "- levels 指定用于层次化索引各级别上的索引\n",
    "- names 用于创建levels上的名称结合上面两项使用\n",
    "- verify_integrity 检查结果对象新轴上的重复情况\n",
    "- ignore_index 不保留连接轴上的索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并重叠数据\n",
    "索引全部或者部分重叠的两个数据集，并且给一点点启发性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Series(\n",
    "    [np.nan,2.5,np.nan,3.5,4.5,np.nan],\n",
    "    index=list('fedcba')\n",
    ")\n",
    "\n",
    "b = Series(\n",
    "    np.arange(len(a),dtype=np.float64),\n",
    "    index=list('fedcba')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(pd.isnull(a),b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[-1] = np.nan\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b[:-2].combine_first(a[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于DataFrame，combine_first自然也会在列上做同样的事情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =DataFrame(\n",
    "    {\n",
    "        'a':[1.,np.nan,5,np.nan],\n",
    "        'b':[np.nan,2,np.nan,6],\n",
    "        'c':range(2,18,4)\n",
    "    }\n",
    ")\n",
    "\n",
    "df2 = DataFrame(\n",
    "    {\n",
    "        'a':[5.,4,np.nan,3,7],\n",
    "        'b':[np.nan,3,4,6,8]\n",
    "    }\n",
    ")\n",
    "df1.combine_first(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重塑和轴向旋转\n",
    "- reshape\n",
    "- pivot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 重塑层次化索引\n",
    "- stack 列 旋转成  行\n",
    "- unstack 行 旋转成 列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame(\n",
    "    np.arange(6).reshape((2,3)),\n",
    "    index=pd.Index(['Ohio','Colorado'], name='state'),\n",
    "    columns=pd.Index(['one','two','three'],name='number')\n",
    ")\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data.stack()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**默认情况下，stack/unstack操作的是最内层**\n",
    "传入分层level的编号或名称即可以对其进行操作\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.unstack('state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = Series([0,1,2,3], index=['a','b','c','d'])\n",
    "s2 = Series([4,5,6], index=['c','d','e'])\n",
    "data2 = pd.concat([s1,s2],keys=['one','two'])\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.unstack().stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.unstack().stack(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在对DataFrame进行unstack操作时，作为旋转轴的级别将会成为结果中的最低级别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(\n",
    "    {\n",
    "        'left':result,\n",
    "        'right':result +5\n",
    "    },\n",
    "    columns=pd.Index(['lift','right'],name='side')\n",
    ")\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unstack('state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unstack('state').stack('side')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将长格式转换为宽格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间序列数据通常是以所谓的“长格式”或“堆叠格式”存储在数据库和CSV中\n",
    "- 长格式 long\n",
    "- 堆叠格式 stack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XXXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldata[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = ldata.pivot('date', 'item', 'value')\n",
    "pivoted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldata['values2'] = np.random.randn(len(ldata))\n",
    "ldata[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = ldata.pivot('date','item')\n",
    "pivoted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted['value'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstacked = ldata.set_index(['date', 'item'] ).unstack('item')\n",
    "unstacked[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据转化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 移除重复数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame(\n",
    "    {\n",
    "        'k1':['one']*3+['two']*4,\n",
    "        'k2':[1,1,2,3,3,4,4]\n",
    "    }\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['v1'] = range(7)\n",
    "data.drop_duplicates(['k1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用函数或映射进行数据转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = DataFrame({'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami', \n",
    "                           'corned beef', 'Bacon', 'pastrami', 'honey ham',\n",
    "                           'nova lox'],\n",
    "                  'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_to_animal = { \n",
    "    'bacon': 'pig', \n",
    "    'pulled pork': 'pig', \n",
    "    'pastrami': 'cow', \n",
    "    'corned beef': 'cow', \n",
    "    'honey ham': 'pig', \n",
    "    'nova lox': 'salmon'\n",
    "}\n",
    "data['food'].map(str.lower).map(meat_to_animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['food'].map(lambda x: meat_to_animal[x.lower()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 替换值\n",
    "- fillna\n",
    "- map\n",
    "- replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = Series(\n",
    "    [1.,-999,2,-999,-1000,3]\n",
    ")\n",
    "print ( data )\n",
    "\n",
    "#1 -> 1\n",
    "print ( data.replace(-999,np.nan) )\n",
    "\n",
    "\n",
    "print ( data.replace( [-999, -1000] ,np.nan) )\n",
    "\n",
    "\n",
    "#list -> list\n",
    "print ( data.replace( [-999, -1000], [np.nan,0] ))\n",
    "\n",
    "#dict \n",
    "print ( data.replace( {-999: np.nan, -1000:0} ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重命名轴索引\n",
    "**轴标签也可以通过函数或映射进行转换**\n",
    "- rename\n",
    "- map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrame(np.arange(12).reshape((3, 4)),\n",
    "                 index=['Ohio', 'Colorado', 'New York'],\n",
    "                 columns=['one', 'two', 'three', 'four'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index\n",
    "data.index.map(str.upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(index=str.title, columns=str.upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(index={'OHIO':'INDIANA'},inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 离散化和面元划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = [20,22,25,27,21,23,37,31,61,45,41,32]\n",
    "bins = [18,25,35,60,100]\n",
    "cats = pd.cut(ages, bins)\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cats.label\n",
    "#cats.levels\n",
    "cats.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['Youth', 'YoungAdult', \n",
    "               'MiddleAged', 'Senior']\n",
    "pd.cut(ages, bins, labels=group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(1000)\n",
    "cats = pd.qcut(data,4)\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.qcut(data, [0,0.1,0.5,0.9,1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 检验和过滤异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "data = DataFrame(np.random.randn(1000,4))\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = data[3]\n",
    "col[np.abs(col) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(np.abs(data) > 3).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[np.abs(data) > 3] = np.sign(data)*3\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 排列和随机采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(np.arange(5*4).reshape(5,4))\n",
    "sampler = np.random.permutation(5)\n",
    "sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.take(sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.take(np.random.permutation(len(df))[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = np.array([5,7,-1,6,4])\n",
    "sampler = np.random.randint(0,len(bag),size=10)\n",
    "sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws = bag.take(sampler)\n",
    "draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 计算指标/哑变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(\n",
    "    {\n",
    "        'key':list('bbacab'),\n",
    "        'data1':range(6)\n",
    "    }\n",
    ")\n",
    "print( df )\n",
    "pd.get_dummies(df['key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df['key'], prefix='key')\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_dummy = df[['data1']].join(dummies)\n",
    "df_with_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnames = ['movie_id','title','genres']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('pydata/ch02/movielens/movies.dat',\n",
    "                     sep= '::',\n",
    "                     header= None,\n",
    "                     names= mnames\n",
    "                    )\n",
    "movies[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_iter = (set(x.split('|')) for x in movies.genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = sorted( set.union(*genre_iter) )\n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = DataFrame(np.zeros((len(movies), len(genres))), \n",
    "                    columns=genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,gen in enumerate(movies.genres):\n",
    "    dummies.loc[i,gen.split('|')] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_windic = movies.join(dummies.add_prefix('Genre_'))\n",
    "movies_windic.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.random.rand(10)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0,0.2,0.4,0.6,0.8,1]\n",
    "pd.get_dummies(pd.cut(values, bins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字符串操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 字符串对象方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 'a,b, guido'\n",
    "val.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = [x.strip() for x in val.split(',') ]\n",
    "pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first, second, third = pieces\n",
    "first+'::' + second + '::' + third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'guido' in val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.index(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.find(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.count(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.replace(',', '::')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.replace(',','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python内置的字符串方法**\n",
    "- count\n",
    "- endwith, startwith\n",
    "- join\n",
    "- index\n",
    "- find\n",
    "- rfind\n",
    "- replace\n",
    "- strip, rstrip, lstrip\n",
    "- split\n",
    "- lower, upper\n",
    "- ljust, rjust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正则表达式\n",
    "re模块的函数可以分为三个大类\n",
    "- 模式匹配\n",
    "- 替换\n",
    "- 拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"foo    bar\\t baz.   \\tqux\"\n",
    "re.split('\\s+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile('\\s+')\n",
    "regex.split(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Dave dave@google.com Steve \n",
    "steve@gmail.com\n",
    "Rob rob@gmail.com\n",
    "Ryan ryan@yahoo.com\n",
    "\"\"\"\n",
    "pattern = r'[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,4}'\n",
    "# re.IGNORECASE makes the regex case-insensitive \n",
    "regex = re.compile(pattern, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = regex.search(text)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[m.start():m.end()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regex.match(text))\n",
    "print(regex.sub('REDACTED',text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P232 \n",
    "In [235]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**正则表达式方法**\n",
    "- findall,finditer\n",
    "- match\n",
    "- search\n",
    "- split\n",
    "- sub, subn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas中矢量化的字符串函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Dave': 'dave@google.com', 'Steve': 'steve@gmail.com', \n",
    "        'Rob': 'rob@gmail.com', \n",
    "        'Wes': np.nan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Series(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.str.contains('gmail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " data.str.findall(pattern, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = data.str.match(pattern, flags=re.IGNORECASE)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.str.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.str[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**矢量化的字符串方法**\n",
    "- cat\n",
    "- contains\n",
    "- count\n",
    "- endswith, startswith\n",
    "- findall\n",
    "- get\n",
    "- join\n",
    "- len\n",
    "- lower, upper\n",
    "- match\n",
    "- pad\n",
    "- center\n",
    "- repeat\n",
    "- replace\n",
    "- slice\n",
    "- split\n",
    "- strip, rstrip, lstrip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例： USDA视频数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "db = json.load(open('pydata/ch07/foods-2011-10-03.json'))\n",
    "len(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[0]['nutrients'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients = DataFrame(db[0]['nutrients'])\n",
    "nutrients[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_keys = ['description', 'group','id','manufacturer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = DataFrame(db, columns=info_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.value_counts(info.group)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients = []\n",
    "for rec in db:\n",
    "    fnuts = DataFrame(rec['nutrients']) \n",
    "    fnuts['id'] = rec['id'] \n",
    "    nutrients.append(fnuts)\n",
    "    \n",
    "nutrients = pd.concat(nutrients, ignore_index=True)\n",
    "    \n",
    "nutrients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients = nutrients.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mapping = {'description': 'food',\n",
    "               'group': 'fgroup'\n",
    "              }\n",
    "info = info.rename(columns=col_mapping, copy=False )\n",
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mapping = {\n",
    "    'description':'nutrient',\n",
    "    'group': 'nutgroup'\n",
    "}\n",
    "nutrients = nutrients.rename( columns=col_mapping, copy=False)\n",
    "nutrients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndata = pd.merge(nutrients, info, on='id', how='outer')\n",
    "ndata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata.loc[30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ndata.groupby(['nutrient', 'fgroup'])['value'].quantile(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Zinc, Zn'].sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_nutrient = ndata.groupby(['nutgroup', 'nutrient'])\n",
    "\n",
    "get_maximum = lambda x: x.xs(x.value.idxmax())\n",
    "get_minimum = lambda x: x.xs(x.value.idxmin())\n",
    "\n",
    "max_foods = by_nutrient.apply(get_maximum)[['value','food']]\n",
    "\n",
    "max_foods.food = max_foods.food.str[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_foods.loc['Amino Acids']['food'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
